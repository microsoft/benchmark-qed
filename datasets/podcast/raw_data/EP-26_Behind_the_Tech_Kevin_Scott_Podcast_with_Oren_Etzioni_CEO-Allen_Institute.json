{"episode": "EP-26 Behind the Tech Kevin Scott Podcast with Oren Etzioni CEO-Allen Institute", "text": "OREN ETZIONI: Whose responsibility is it? The responsibility and liability has to ultimately rest with a person. You can\u2019t say, \u201cHey, you know, look, my car ran you over, it\u2019s an AI car, I don\u2019t know what it did, it\u2019s not my fault, right?\u201d You as the driver or maybe it\u2019s the manufacturer if there\u2019s some malfunction, but people have to be responsible for the behavior of the machines. \n\n[MUSIC]\n\nKEVIN SCOTT: Hi, everyone.  Welcome to Behind the Tech.  I'm your host, Kevin Scott, Chief Technology Officer for Microsoft. \n\nIn this podcast, we're going to get behind the tech.  We'll talk with some of the people who have made our modern tech world possible and understand what motivated them to create what they did.  So, join me to maybe learn a little bit about the history of computing and get a few behind-the-scenes insights into what's happening today.  Stick around.  \n\n[MUSIC]\n\nCHRISTINA WARREN: Hello, and welcome to Behind the Tech. I\u2019m Christina Warren, senior cloud advocate at Microsoft. \n\nKEVIN SCOTT: And I\u2019m Kevin Scott. \n\nCHRISTINA WARREN: Today on the show, our guest is Oren Etzioni. Oren is a professor, entrepreneur, and is the chief executive officer for the Allen Institute for AI. So, Kevin, I\u2019m guessing that you guys have already crossed paths in your professional pursuits. \n\nKEVIN SCOTT: Yeah, I\u2019ve been lucky enough to know Oren for the past several years. We met after I became CTO at Microsoft, but I\u2019ve been very, very well aware of Oren professionally for many, many years. \n\nThe thing he probably doesn\u2019t know is the University of Washington, where he still is a professor, was one of the places that I wanted to go to graduate school. So, the entire time I was in undergrad, I had a copy of the UW computer science course catalog sitting on my desk as an aspirational thing. I was following his work pretty closely back then, which you know, may sound a little bit creepy, I guess. (Laughter.) \n\nCHRISTINA WARREN: Well, you know, no, I don\u2019t think it\u2019s creepy. I mean, you\u2019re a fan, and I think that\u2019s awesome that you know each other now, and now we\u2019re going to be able to get into the interview and hear you guys talk. \n \n\nKEVIN SCOTT: Yeah, Oren is \u2013 he\u2019s really an amazing teacher, leader, and scholar in the work that he\u2019s doing with the Allen Institute for AI is really incredible. So, I\u2019m super glad to have him on the show today. \n\nCHRISTINA WARREN: Likewise. Likewise. Well, let\u2019s get to the interview. \n\n[MUSIC]\n\nKEVIN SCOTT: Our guest today is Dr. Oren Etzioni. Oren is chief executive officer at the Allen Institute for Artificial Intelligence. He\u2019s been professor at the University of Washington\u2019s Computer Science Department since 1991. His awards include Seattle\u2019s Geek of the year in 2013 and he\u2019s founded or co-founded several companies including Farecast and Decide.com.  \n\nOren has helped pioneer metasearch, online comparison shopping, machine reading, and open information extraction. Welcome to the show.  \n\nOREN ETZIONI: Thank you, Kevin, it\u2019s a real pleasure. \n\nKEVIN SCOTT: So, I would love to get started by talking a little bit about how you got interested in science and engineering in the first place. Was it when you were a little kid or later on in life? \n\nOREN ETZIONI: Well, both my parents are sociologists, actually, professors of sociology. And so, I think instinctively, subconsciously, I ran away from that as far as I could. Like some of your other guests, like Daphne Koller and I think yourself, I discovered that magical machine via the TRS-80 and started playing with it. It was just really fun and really new, and I kinda could sense something very powerful there.  \n\nBut where I really got engaged was when I read the book Godel, Escher, Bach, which many of us did back in the day. I got kind of a whiff of the questions that we could be asking and that we could be studying using computers are really some of the most fundamental intellectual questions of all time. What is the origin of the universe? What is the nature of intelligence? How do we build an intelligent machine? \n\nKEVIN SCOTT: Yeah. I mean, it\u2019s really interesting that so many of us have such an interestingly similar experience. I can\u2019t remember \u2013 I think I was in college when I read Hofstadter\u2019s book the first time \u2013 or tried to read it \u2013 because it is intellectually dense. But it really had a remarkable impact on a bunch of people. And I\u2019m guessing it still sort of informs some of the things that you\u2019re doing today, because you know, in a sense, what all of us are doing a little bit with the pursuit of artificial intelligence is not just figuring out what the machines are capable of, but like what does that say about human intelligence itself, which we really don\u2019t understand in a deep sense? \n\nOREN ETZIONI: That\u2019s exactly right. One way to think about artificial intelligence or I\u2019ll just use \u201cAI\u201d for short, is really it\u2019s almost a funny pun or homonym. It really, in my mind, refers to two very different things. One is a set of technological capabilities, which I\u2019m sure we\u2019ll talk about some more, but are getting increasingly powerful with speech recognition, with facial recognition, with things like GPT-3, and at the same time, it\u2019s a kind of vision, right, of how do we build human-level intelligence, artificial general intelligence, and so on. \n\nAnd those two things are actually very different in the sense \u2013 in my opinion \u2013 in the sense that the technology is progressing very well, but it\u2019s still very, very far off from the ultimate vision of the field. \n\nKEVIN SCOTT: Yeah, well, and you know, I think the interesting thing that we all have seen over the past several decades is we keep solving these problems that we think are reflective of high human intelligence, and as soon as we\u2019ve solved them, we decide that, \u201cOh, well, maybe that wasn\u2019t really what is the core of human intelligence.\u201d \n\nYou know, I remember when it was chess playing and then it was Go playing and then it\u2019s these feats of perception that we\u2019ve been able to do and, you know, like, there are still these things that are \u2013 for human beings, like, very, very easy that I don\u2019t think we think of as being cognitively sophisticated that completely elude the ability of machines \u2013 common sense reasoning, navigating physical environments, and all sorts of fun stuff. \n\nSo, you know, I do think we have been confused about what the definition of intelligence is for a very long while now, which makes going after it interesting. (Laughter.) \n\nOREN ETZIONI: Well, what you\u2019re saying is so true, right? There are writings in the \u201860s and the \u201870s and later talking about, say, chess, right, as the pinnacle of intelligence. And you can sort of see why, right? For most people, playing Grandmaster Chess is an incredible feat of intelligence. Very elusive. And then to find out that the machine can do it is startling. \n\nAt the same time, there is something called Moravec\u2019s Paradox, right, that says things that are easy for the machine are hard for people \u2013 like playing champion-level chess or Go. Conversely, things that are easy for people \u2013 like you said, common sense, crossing the street, driving a car \u2013 most people can do it with reasonable success, and machines are still surprisingly far away. \n\nI would say, however, that one remarkable thing, which of course you\u2019re familiar with, is the articulation of \u201cHow can we tell if a machine achieved intelligence?\u201d by Alan Turing in the \u201850s, and he devised the Turing Test. And while the Turing Test sometimes is misapplied, it becomes \u2013 so, to define it, right, the Turing Test is you\u2019re communicating with somebody, let\u2019s say over, I don\u2019t know, Twitter or Slack or Microsoft Teams, I should say \u2013 whatever it is \u2013 and you don\u2019t know whether it\u2019s a person or a machine, and you have to try and guess.  \n\nWhen you can\u2019t tell them apart, then the machine is said to have passed the Turing Test. Now the thing is, if it\u2019s misapplied, it becomes a test of human gullibility, right? We can trick people into thinking, \u201cOh, yeah, I\u2019m talking to a person.\u201d But if it\u2019s done right, if you subject it to a rigorous test by, say, a panel of experts, then it\u2019s actually quite an achievement, right, to have a machine that behaves intelligently, et cetera, et cetera. \n\nSo, I think we have that notion. The problem is that we take these narrow slices, like playing chess or like, I don\u2019t know, solving the Rubik\u2019s Cube. And it\u2019s not surprising, by the way, that they\u2019re often in artificial domains, that they\u2019re often games and such. And we say, \u201cOh, that\u2019s intelligence.\u201d And then we find out, well, not quite. \n\nKEVIN SCOTT: Well, and you know, I think yeah, you pointing out that they are in these artificial domains is an interesting thing for all of us to recognize about the state that AI is in right now, and where it is likely to be in the near future. So, I think some of the things that we may think are insulated from encroachment by AI, like a bunch of white collar work, for instance, is actually far more likely to have AI impact it than things like manual labor, for instance. Where, because we haven\u2019t solved these problems where the AI has to interface with the physical world, it just \u2013 like, we haven\u2019t even figured out the basic experimentation loop for solving that problem. \n\nSo, like, we can\u2019t iterate there nearly as fast as we can in these artificial domains, where progress is still pretty good. I don\u2019t know whether you would agree with that or not. \n\nOREN ETZIONI: I think it\u2019s a very rich topic, but I definitely agree with what you\u2019re saying, that the speed of experimentation and iteration makes a huge difference. So if you\u2019re dealing with a robot, say, right? And every experiment that goes awry, you can break a robot arm, or god forbid, hurt somebody, obviously, that slows things down so people work in simulation. Then, the simulation doesn\u2019t necessarily map to the real world. \n\nWhereas in games, right, with self-play, the computer can play each other and very quickly gather millions of training examples. \n\nYou know, the way I think about this topic is if something is very rote, you do the same thing every time \u2013 like collecting tolls or operating elevators, those things are not great jobs, right? I mean, is that really \u2013 you know, hopefully we can find people better jobs than those. And those are easy for the machine to do. \n\nThen, the next level is making binary distinctions, right, or categorizing things. For example, take email, is it spam or is it not spam? When you have a huge number of emails \u2013 literally billions \u2013 you can train up a really good model that says yes or no. \n\nBut when it\u2019s much more complicated, like how do I design a good podcast? How do I be the CTO of a major company? I think, Kevin, you\u2019ve got job security. We\u2019re not going to be replacing you with a program anytime soon. \n\nKEVIN SCOTT: I don\u2019t know, maybe that would be nice. (Laughter.) \n\nOREN ETZIONI: Well, what would be nice is to have a program that helps you, right? \n\nKEVIN SCOTT: Yeah. \n\nOREN ETZIONI: So, a lot of the work that we do and a lot of the work elsewhere really can think of AI as \u201caugmented intelligence.\u201d Would you be more effective at your job if you had a program that helped, I don\u2019t know, prioritize your emails, right? That helps you author emails more efficiently or even papers, right, all that.  \n\nKEVIN SCOTT: Yeah, so let\u2019s go back a minute. So, you found the TRS-80 when you were a kid, you read, you know, Godel, Escher, Bach like was that when you were in high school or in college? \n\nOREN ETZIONI: In high school, yeah. \n\nKEVIN SCOTT: Yeah, so as a high school student you read this, like, really formative book. And then did you major in computer science when you went to university?  \n\nOREN ETZIONI: Well, actually, it was \u2013 I\u2019ll share with you a quick little anecdote. So, when I went to college, I went to what I like to call a small community college in Cambridge, Massachusetts, but it has the august name of Harvard. They didn\u2019t have a computer science major. They had applied math. And they \u2013 their approach, I heard this from some of the professors there, was viewing computer science as more of a kind of applied discipline. They said, \u201cHey, we don\u2019t have a major in automotive science, so why would we have a major in computer science?\u201d\n\nAnd right around the time I was there, so this is 1992, 1993, right at the beginning of my time there, they realized, no, this isn\u2019t a fad, and this isn\u2019t some applied discipline, it\u2019s quite transformative. Again, I wasn\u2019t privy to those discussions as a freshman. All I know is they did create a new concentration, as it\u2019s called. And being an eager beaver, I ran to Howard Lewis to declare my new concentration and he signed my paper form, if you can believe that. And he raised his head and he said, \u201cHey, you\u2019re the first.\u201d \n\nSo, I feel like my \u2013 I\u2019ll go down in \u2013 \n\nKEVIN SCOTT: Wow. \n\nOREN ETZIONI: -in history as the first person to major in computer science at Harvard. \n\nKEVIN SCOTT: That is so cool. That\u2019s really, really neat. And so, what was that program like? Because I\u2019m guessing, you know, given that it was early days, and this was true even when I was a freshman in 1990, and like even in 1990, we were still trying to figure out, like, what a computer science curriculum looked like and, you know, like the entire, you know, ferment of the field was just sort of being developed.  So, what was it like being that first student? \n\nOREN ETZIONI: Well, so, again, they\u2019d been teaching computer science courses for a while, it was just under applied math. And I would say that the Harvard curriculum was very mathematical, so it was influenced by people like the great Michael Rabin, Turing Award winner, inventor of some of the key theorems in theoretical computer science. Les Valiant was there, you know, teaching combinatorics. So, it was a very theoretical curriculum, which I actually really appreciated because, you know, you want to get that mathematical grounding right. \n\nBut at the same time, there was very little AI. So, I was fortunate that, you know, two T stops away was MIT and tech square, and so very quickly I started hanging out at MIT, where Minsky was there and actually Hofstadter, who was, you know, a god for me at the time, was visiting for a year or two. And so, I felt like I was very fortunate because I got my AI at the MIT AI lab and I got my computer science grounding and broader education at Harvard. So, that was really a wonderful time. \n\nKEVIN SCOTT: Yeah, and then you fell in love, I\u2019m asking, not asserting. You fell in love with, you know, with computer science \u2013 with the field, and decided to go to graduate school and get a PhD? \n\nOREN ETZIONI: So, again, what I was really in love with is the fundamental questions. For me, computer science and computers was always a tool. And, actually, I was also studying cognitive science and philosophy of language science at the time, and I was debating whether I should go to grad school in philosophy or in computer science, because these were methodologies for me to get at these fundamental questions. \n\nAnd then I talked to some people and I realized the people were graduating with a PhD in philosophy and working in moving, right, it was not a great career path. Whereas I could tackle these issues in a more empirical way and, frankly, just a more satisfying from a career point of view way, as a computer scientist. So, I decided to go to grad school in computer science.  But it wasn\u2019t obvious. I could have ended up being a philosopher. \n\nKEVIN SCOTT: And what was your dissertation on? \n\n\nOREN ETZIONI: So, I went on to study with Tom Mitchell, who\u2019s really the father of machine learning or one of them in many ways. It was on machine learning, a subfield of machine learning that\u2019s much more symbolic than the kind of neural network deep learning stuff that we do today. \n\nKEVIN SCOTT: Yeah, but he must have even been thinking about statistical methods back then. I\u2019ve got, like, one of Tom\u2019s textbooks that I\u2019ve had for a very long time. And I think it\u2019s the first place that I ever read about Bayesian inference. So, I don\u2019t know whether he was thinking about things like the statistical approach to machine learning back when you were his student or not, but he certainly has done some interesting work there. \n\nOREN ETZIONI: Absolutely. He was and he did, and his classic textbook covered it. Geoff Hinton was visiting at the time, and there was very lively and intense discussion of his ideas. I think the thing that Tom and certainly I missed was the power, the potential power of neural networks to \u2013 when you have awesome amounts of data and tremendous amounts of computational power. So, at the time, they didn\u2019t necessarily do better than other statistical mechanisms. So, it was very clear that we wanted statistical methods, but it was a lot less clear that we wanted neural networks. \n\nKEVIN SCOTT: I think that\u2019s one of the sort of classical timing problems in computer science and engineering, where it was a good idea, but because \u2013 we effectively didn\u2019t have the data volume and the distributed computing infrastructure that came along with the internet revolution and like these big internet companies and their distributed computing and cloud infrastructure, which wasn\u2019t called cloud infrastructure at the time. \n\nAnd so, I just sort of wonder what are we missing right now? Like, the good ideas that happened 10 years ago that are, you know, left by the wayside that are now feasible and like we don\u2019t even have someone \u2013 I mean, the good thing about Geoff is he was stubborn, like, he was convinced that it was a good idea and he kept pushing on it, you know, for a very long time until the conditions were right for it to be successful. \n\nAnd I just sort of wonder, like, you know, what conditions are going to change in the future that are going to make you know some of the things that are infeasible now actually possible? It\u2019s one of the reasons why I\u2019m like really excited about all of this large-scale compute infrastructure that we\u2019re building right now, because like it\u2019s just \u2013 it may not get us to AGI, which is a thing I do want to talk to you about in a minute, but it certainly gets us something, and I\u2019m really interested to see what that something is. \n\nOREN ETZIONI: Me too. I think it\u2019s a really interesting time to be a computer scientist, to be a computer professional. I do want to say, off the top of my head, here are three things that the current technology doesn\u2019t yet touch. The first one is the current technology \u2013 maybe this is a good phrase \u2013 is kind of profligate in its use of compute and data. Yeah, I need millions of examples at least for pre-training and then thousands for tuning. Yeah, I need this massive amount of computation, millions of dollars of computation to build my model. \n\nWhereas of course human intelligence, which is the standard, sits in this little box, right, that\u2019s on top of my neck and is powered by the occasional salad and a cup of coffee, right? We know, right, you know, kids, they\u2019ll see one example and they\u2019ll go to the races. So, I think we can build far more frugal machines in terms of data and compute, that\u2019s one. \n\nAnd then the second thing, and this goes right back to the discussions we were having at CMU in the early \u201890s is, \u201cWhat is the cognitive architecture?\u201d In other words, okay, you can take a narrow question like, \u201cIs this email spam or not,\u201d or \u201cDid I just say \u201cB\u201d or \u201cP?\u201d Speech - phoneme recognition. And you can train models that\u2019ll do \u2013 they have super-human performance at that. \n\nBut the key thing in artificial general intelligence \u2013 in AGI \u2013 is the \u201cG.\u201d So, how do we build what was called, then, a unified cognitive architecture? How do we build something that can really move fluidly from one task to another, when you form a goal, automatically go and say, \u201cOkay, here\u2019s a subgoal, here\u2019s something I need to do or learn in order to achieve my goal.\u201d There\u2019s just so much more to general intelligence than these savant-like tasks that AI is performing today. \n\n\nThe third topic in AI that I think we ought to be paying more attention to is the notion of a unified cognitive architecture. So, this is something we studied at CMU back in the day. And it\u2019s the notion of not just being a savant, not just taking one narrow problem, but going from one problem to the next and being able to fluidly manage living, where right now we\u2019re talking. Soon, I will be crossing the street, then I\u2019ll be reading something. \n\n\nPutting all those pieces together and doing it in a reasonable way is something that\u2019s way beyond the capabilities of AI today. \n\nKEVIN SCOTT: Yeah, and we\u2019ve got a little bit of that starting \u2013 \n\nOREN ETZIONI: I know, I \u2013 \n\nKEVIN SCOTT: In transfer learning, like, but just beginning. \n\nOREN ETZIONI: Right, but the thing about the transfer learning is that it\u2019s still from one narrow task to another. Maybe it\u2019s from one genre of text to another genre of text. We don\u2019t really have transfer learning from, okay, I\u2019m reading a book, to now I can take what I read in the book and apply it to my basketball game, right? We\u2019re very far from anything like that. \n\nKEVIN SCOTT: Yeah, the other thing that I\u2019m also really curious about, we\u2019ve \u2013 you know, we\u2019ve chatted with some people on the podcast who are doing research on insect biomechanics, for instance. You know, which \u2013 and they\u2019ve done very, very detailed studies of, like, what the neural architecture is for the control systems that manage insect flight and navigation, for instance. \n\nAnd they are very, very highly specialized neural circuits. It\u2019s not a, you know, sort of a general like deep network that you know \u2013 like maybe a deep network could learn that behavior, but like there\u2019s certainly \u2013 there seems to be an efficiency opportunity. \n\nAnd like I could not more strongly agree with that point. I forget what the numbers are, but if you look at like the world champion Go player, Lee Sedol, like, he probably got to world-champion levels of expertise on a small number like, low tens of thousands of hours\u2019 worth of game play, which is like more than you or I would ever be willing to commit, but far, far less than the millions of simulated hours that a thing like AlphaGo Zero invested to get to the point where it could play competitively with him. \n\nAnd that is \u2013 you know, that amounts to millions of dollars and millions of watts of power and it\u2019s a very, very interesting chasm that I think we have an opportunity to cover at some point \u2013 hopefully in the not-too-distant future. \n\nOREN ETZIONI: Absolutely. You know, at the Allen Institute, we\u2019ve recently written a paper that\u2019s going to appear in Communications of the ACM on something we call \u201cgreen AI.\u201d And the idea of it is both to think about the carbon footprint, right, and the \u201cCan we build these more efficient systems?\u201d But there\u2019s another thread here that I want to highlight, which is making sure that the research that we\u2019re doing is sufficiently inclusive. \n\nSo, back in the day, it used to be that you or I or a talented undergraduate in India or some other country with a laptop could do something really cool and write a paper about it and get noticed. If we reach the point where you have to have so much infrastructure and so much compute to do an experiment that leads to a published paper, that\u2019s a real problem for the field, right? We don\u2019t get to harness all the brilliant ideas and creativity of a broader population. And so we suggested some pragmatic ideas of how to fix that not by, you know, forbidding or cutting off this very exciting, high-end research, but by saying, \u201cOkay, let\u2019s also look at efficiency, at results of, okay, how can we run these types of models on a much more limited device?\u201d\n\nKEVIN SCOTT: But I\u2019m so glad to hear that you all have written that paper and are pushing on that because I do think it\u2019s one of the fundamental issues that we\u2019ve got at this particular moment in time with AI research, these models are not only extremely expensive to train, they are extremely expensive to serve. So, you\u2019ve got this cost thing that makes it difficult to make them widely available. \n\nI mean, like, we could \u2013 I\u2019ll give you an example. I won\u2019t talk about GPT-3, but I\u2019ll talk about this model that we built called Turing NLG, which is a 17-billion parameter transformer model. \n\nOREN ETZIONI: Only 17 billion. \n\nKEVIN SCOTT: Yeah, only 17 billion. So, like, it was extremely \u2013 I mean, we trained this on a very large, very sophisticated cluster of GPUs and it consumed a lot of resources and like we wrote a bunch of very specialized software to manage the distributed training task. \n\nAnd the model is very, very powerful. And so, one of the things that we\u2019re struggling with right now is -  I would love to get that model into the hands of as many people as humanly possible. One impediment to getting it into the hands of as many people as possible is cost. And like I think, you know, to your point, we can bring the costs down by, you know, making a whole bunch of these investments. Like, the infrastructure could be better. You can distill the model, there\u2019s all sorts of like really interesting things that you can do to like still preserve the model\u2019s power and make it much cheaper to serve. \n\nBut the other, you know, interesting thing with these models is it\u2019s a general language model. It will enable people to put it in use cases that we would find objectionable. And like by \u201cwe\u201d I don\u2019t mean Microsoft, I mean \u201cwe\u201d society. And so you know, it\u2019s \u2013 and I don\u2019t know how you train the model to allow it to do all of the powerful things that it can do and exclude the objectionable things that we\u2019re not going to want it to do. \n\nAnd so that is another thing that makes access a little bit tricky. So, like, how do you get that into the hands of responsible people so that they can discover all of the good uses that the tech companies that have the resources to build these models will never be able to imagine on their own without, you know, opening Pandora\u2019s box and creating more misery in the world. \n \nOREN ETZIONI: Very important questions. The good news is, I do think that we\u2019re making progress there. So, some of it is the old adage, garbage in, garbage out. So, you have to be careful what you feed. This model is kind of like an innocent child, right, who will read anything. So, you have to be careful what you feed it. \n\nThat\u2019s typically not enough, because these things consume, right, you know, billions and billions of sentences and documents. I\u2019m a great believer in auditing techniques. So, we also need to make models like this eternally auditable so other bodies can help discover if there\u2019s, you know, problems hidden there or if it can be tuned in a negative direction. So, I do think that you and Microsoft are very smart to think carefully about these issues, but I do think that help is on the way.  \n\nKEVIN SCOTT: Yeah, well, and that I think is one of the foundational things I would like to be able to figure out sooner rather than later is just a way to allow the help to happen in an efficient and transparent and open manner, because at least that much needs to be happening. \n\nIt would have very ironic to have a situation where the very, very necessary public and open work that needs to happen on responsibility and safety and ethics and all of these other things can\u2019t happen because the people who are doing that work outside of corporations don\u2019t have access to the models.  \n\nOREN ETZIONI: Well, so then if I may ask you a question, right, with GPT-3 and Microsoft\u2019s recent exclusive ability to license it, are you planning to make it available to academia, to places like AI2? \n\nKEVIN SCOTT: Yeah, we\u2019re trying to figure out exactly how to do that right now. Like, in a safe way and \u2013 I mean, the thing with GPT-3 is, like, it\u2019s, you know, it\u2019s ten times bigger even than the Turing NLG model that we built. \n\nAnd so there, we probably will have to serve it on our infrastructure just because the task of figuring out how to \u2013 like, if I gave you a bag of weights or we gave you a bag of weights and then you had to go figure out how to serve it for doing your research, like, that would be its own research project that would be daunting. And so, like, we are working through those issues right now.  \n\nOREN ETZIONI: Well, I\u2019m glad to hear it. And, of course, you\u2019re absolutely right. With something that big or even the Turing NLG model, right, what people really want is an API, not a file that you download with lots of numbers in it.  \n\nKEVIN SCOTT: Yeah, and so the nice thing about an API is it lets you, through like the access control to the API, like, have some sort of, you know, guarantees around responsible use. And then it just \u2013 it really does become about cost. \n\n[32:29]\nAnd, you know, cost is \u2013 we want to be able to get the cost down to the point where you can do reasonable amounts of inference and exploration with the model in a way that doesn\u2019t break my personal budget at Microsoft. (Laughter.) \n\nOREN ETZIONI: Sure, which I\u2019m sure is quite sizable. But here\u2019s a simple idea that we advocated in the Green AI paper. The reporting standards, when we report accuracy of models, you know, how often they get things right, are very clear and so on. But the reporting standards on how much did it cost you to produce that performance, aren\u2019t. People often don\u2019t report that, or if they do, they don\u2019t report some of the dead ends that they went into. \n\nIf they reported that more rigorously, then as you said, the distillation efforts \u2013 basically, the efforts to build a cheaper model, maybe a far-cheaper one, would be a lot easier. Because I could say, okay, here\u2019s your model, it costs, let\u2019s say, $100,000 to train it. Here\u2019s my model. It only performs 70% at the level of your model, but you know what? It costs 1/10th to produce. \n\nOr here\u2019s my model, maybe it\u2019s only 40% of your model, but I can run it on a phone. So, the \u2013 but I can only publish that result if I have a baseline, right? And that baseline has to include the cost, because then I can make that. \n\nSo, a really simple step on the part of everybody \u2013 kind of the rich players in the ecosystem of simply being rigorous on reporting their costs would enable everybody else to start whole new \u2013 really sub areas of the field. \n\nKEVIN SCOTT: Yeah, I think that\u2019s an interesting idea and, certainly, something we will think about. I mean, one of the interesting things that I\u2019ve seen in \u2013 so, my Microsoft Research reports to me at Microsoft. And, you know, one of the things that we\u2019ve struggled with this same thing even internally, right? So, like, you may imagine that, you know, Microsoft is you know like has a very big capital and R&D budget, which means that you know, once we have one of these models, then everyone can use it, which isn\u2019t even true internally. \n\nSo, you know, the amount of resources required to train a very big model and then to, like, go serve it in an application where you may have a billion users is \u2013it\u2019s sort of daunting on the training side, there\u2019s just limited amount of compute. \n\n[34:15]\nAnd so, like, you have to decide who is going to be training what. And on the serving side, we really do very carefully measure how much it costs to, you know, in terms of compute and power and depreciation on the capital for a single API call to a thing, because we have to make sure that when we\u2019re putting it into a product or a service that you know, you\u2019re profitable still. \n \nAnd, so, you know, our teams inside of the company even have these issues about, like, you know, what engineering work do I have to do to make this thing useful for me? Because we haven\u2019t even sorted the problems of access out inside of the company. And I know for a fact, you know, that everyone is struggling with this right now because these models are so big. \n\nOREN ETZIONI: That makes a lot of sense, yeah. \n\nKEVIN SCOTT: Yeah, so, you started your career \u2013 or early parts of your career, you were doing, you know, a bunch of super-interesting stuff in information retrieval and you \u2013 you know, you were starting companies, you \u2013 like I think may have built the first comparison shopping site on the Web. \n\nHow did you \u2013 it sounds like you\u2019ve always been interested in artificial intelligence, and you know, my question is: Like, have you \u2013 you know, were you always able to see, you know, this through line through all of this stuff that you were doing, like, everything always connects back to AI? Or was it, like, all right, these are just super interesting problems of the moment that I have the skill you know to address and the interest in. \n\nOREN ETZIONI: Anybody who tells you that over a long career and here I\u2019m betraying my age, I\u2019ve been doing this for 30-plus years, there\u2019s a connecting through line and a grand plan is either far smarter than I am, or far more strategic, or is just kind of selling you a bill of goods, you know, the Brooklyn Bridge, as they say. There are themes that I\u2019ve always been fascinated by.  \n\nFor example, all the companies that have started have always been about empowering the consumer with information \u2013 particularly about price, like when to buy your airline ticket, right, that was so you get the best price. That was Farecast, or the first company I co-founded with Professor Dan Weld on online comparison shopping, \u201cWhere do you find the best price?\u201d particularly this was in the world before Amazon. \n\nAmazon was just getting started. So, and it wasn\u2019t just, by the way, about price, it was also about selection, right? Nowadays, we kind of assume we can always find it at a decent price at Amazon, say, but A, sometimes you can get a better price elsewhere, and B, at the time, often it wasn\u2019t clear where to buy a particular good. \n\nSo that was a big theme for me. And the toolkit, we all have our toolkit. Certainly, AI and information retrieval related to that, machine learning, that was my go-to toolkit, so it was natural to go there. \n\nBut I kind of view a lot of these as side adventures. I feel like my two long-term passions are \u2013 one is the fundamental intellectual question of AI that we talked about earlier, \u201cHow do we build an intelligent machine?\u201d  And then the second one is, \u201cHow do we use AI as a technology to make the world a better place?\u201d\n\nAnd, you know, better search engine can do that, better shopping can do that. Right now, at the Allen Institute of AI \u2013 or AI2, as I call it \u2013 a project that I\u2019m particularly proud of is semantic scholar. How do we make scientific research more efficient and more productive using AI? And actually a callout to Microsoft Research and the work on the Microsoft Academic Graph. Right? We\u2019ve made extensive use of those resources to build Semantic Scholar. \n\nKEVIN SCOTT: That is awesome. So, I want to dig a little bit into the particulars of these big models that folks are building right now, particularly around language, although soon they\u2019re going to be multimodal and you know sort of applied to a bunch of different domains. \n\nBut one of the interesting things that you all did. I think this was sometime the middle of last year was this system called Arista that is your test-taking system. And so you\u2019ve been working on this for a really long time, and my understanding is that you were able to leverage some of these newer, self-supervised language models like Google\u2019s BERT model in particular, to finally get the system to the point where it can reach parity with students at taking science tests. Talk a little bit about that.  \n\nOREN ETZIONI: Sure, so this really starts with the late Paul Allen\u2019s vision. And he asked the question, \u201cGosh, if our technology is so great, be it computer science or AI, why can\u2019t it pick up a book \u2013 a textbook \u2013 read the textbook and then answer the questions at the back of the book?\u201d\n\nAnd he had a project even before Allen AI, which started in 2014, he had an earlier project that attempted to do that in various ways and were not successful. \n\nSo, when we launched Allen AI, AI2, in 2014, we said, \u201cWhy don\u2019t we focus on grade school tests?\u201d Let\u2019s work our way up to reading a college-level biology textbook. \n \n\nAnd the way we do that is we\u2019re going to have the program take a fourth-grade science test, and eighth-grade test, take the SATs. And the beautiful thing about that is we can measure the system\u2019s performance and we\u2019ll take it on unseen tests, right, the same way, you know, the Regents New York State publishes a new test every year. \n\nSo, we\u2019ll take an unseen test, the machine has never seen the test before. And like a kid, we\u2019ll measure the performance. We\u2019ll also compare it to human performance. We\u2019ll have a benchmark where we say, \u201cOkay, how is our progress going?\u201d\n\nAnd I think that helped Paul Allen, reassure him that he could get a sense, right, without being there every minute, get a sense of our progress and that we were really making progress rather than building towers in the air. So that became our benchmark is these science tests. And we struggled mightily with these tests in part because it turns out the tests are written in English and they require a lot of background knowledge. They require understanding of various phrases. They have phrases in there like \u201cthe onset of winter.\u201d What the heck is the onset of winter? So, a lot of tricky issues that we don\u2019t have time to get into.  \n\nWe were making steady progress, but it was hard. It was very difficult. We set ambitious goals every year and we struggled mightily to meet them. What happened, as you said, this new class of models came, and they actually originated at AI2. We had a model called ELMO, won the best paper award in 2018. It was quickly followed by Google\u2019s model called BERT, which is a nod to ELMO, won the best paper award in 2019.  \n\nAnd people have gone from there, and Turing NLG, which you mentioned, right, is yet another instantiation. Others have Roberta, et cetera. There are all these models are actually \u2013 I should mention because they\u2019re actually pretty simple. All they do, right, is take a word and say, \u201cWe\u2019re going to figure out what this word means based on its context.\u201d Not its context in one page or one sentence, but in all the places it appears in billions of sentences, we\u2019re going to compute statistics on its context and these statistics are going to enable us to predict if I see a word or a sentence or a phrase, what\u2019s going to come next \u2013 what might even come before \u2013 just based on what typically happens. \n\nIt turns out that that basic idea, with a lot of technical bells and whistles, is incredibly powerful \u2013 more powerful than I think anyone would have anticipated. So, we started using that in our work and we said, \u201cOkay, it\u2019ll help. This tide will boost all boats.\u201d But we never anticipated how much it will help. \n\nSo, we found that very quickly, we were able to get 90% \u2013 at least on the multiple-choice parts of the test \u2013 that involved text. And so, all of a sudden, this model led us to pass and even ace a fourth-grade test, eighth-grade test, even 12th-grade science tests. And that was a surprise. And it leads me to make a prediction. I think that we\u2019re going to see \u2013 we\u2019re already seeing, but we\u2019re going to see even more in the next five years, tremendous applications of natural language all over the world. \n\nThere\u2019s machine translation, which we\u2019ve already seen. There\u2019s \u2013 in the medical and the healthcare system, everywhere where there\u2019s text, which is kind of everywhere, right, because we have text in our emails, we have text in physician records, we have text in scientific papers, we have text in insurance claims, you know, you name an arena of life, I\u2019ll tell you the text that\u2019s there. \n\nOur ability to understand that has really had an inflection point. And that inflection point is going to result in both improved science, but also new startups, new capabilities out of companies like Microsoft and Google. It\u2019s really an exciting time to work on what\u2019s called NLP.  \n\nKEVIN SCOTT: Yeah, it is. I mean, we had a similar phenomenon, I guess, with convolutional neural networks, which like really were a step function improvement in image recognition and like some of these visual domain tasks. But you know, if anything, because so much of our world is about written human language, like, the impact that I\u2019m seeing from these models like ELMO, I mean, it\u2019s just unbelievable. \n\nLike, I completely agree with you about the far-ranging impact and, like, probably we\u2019re going to see an acceleration over the next five years of, you know, companies and applications and all sorts of interesting things. \n\nI want to pick your brain, though, as we reach these inflection points on domains where AI starts to get really good it always comes with implications for what does it mean for you know individual humans and greater society. \n\nLike, one of the things I\u2019ve been really, really asserting to my kids\u2019 teachers are that, you know, we have these systems that already are pretty good at taking standardized tests, and like, we \u2013 you know, we probably don\u2019t want to be training our kids as test-takers, you know, unless there\u2019s some much better understood cognitive benefit of the test-taking activity or you know like it really is a verification that they have you know ingested and learned, like, deeper knowledge than they need just to do the test-taking activity, because the machines are going to be able to take the tests with super-human performance very soon, I would guess. \n\nYou know, which means that \u2013 you know, I\u2019m sure you\u2019re glad that you went to Harvard and you had, like, a pretty diverse training, like, you were interested in cognitive science and mathematics and got a liberal education. And I think liberal education becomes more and more important as we get expert machines in these narrow domains.  \n\nLike, what are some of the other things that you all are thinking about \u2013 because this is part of the AI2\u2019s mission, right, is to think about AI\u2019s impact on the world, like, how are you thinking about these things? \n\nOREN ETZIONI: Well, I think the topic of education in the modern world is near and dear to my heart. You know, I have three kids and a ten-year-old. And I worry both about the fact that they\u2019re not really getting nearly as much computer literacy as I would like, and literacy with statistics and the ability to analyze data, right, which we have more and more of. \n\nThat impacts even their ability to be a good citizen, right? So many of the issues \u2013 let\u2019s take climate change, right, that we face, you know, come to statistics or the issues of what is going to be the role of computers and algorithms in society. \n\nSo, I really think that we do need to have the basics, right? You don\u2019t want people who, you know, can\u2019t read, because the computer will read to me or can\u2019t do arithmetic, right? So, you want to have the basics, but you want to go way beyond that. And you want to develop the skills of working together with the machine. The machine will do its part and the kid will learn to use it in important ways.  \n\nAt AI2, we think about a number of issues not so much having to do with kids and education, but certainly having to do with bias. How do we prevent machines from amplifying the bias that\u2019s in their input data, right? Because these models that we talk about, right, they take typically data from the past, they crunch it in the present, and then they make predictions or even decisions in the future.  \n\nSo, if our past has racism and sexism and other \u2018-isms\u2019 that are very unfortunate, or more than unfortunate, they can be horrific, the last thing we want to do is carry them forward to the future. \n\nAnd, again, that\u2019s a very hot area of research, both at AI2 and more broadly we had a paper a few years ago won the best paper award called Men Also Like Shopping, that looked at the bias that\u2019s actually in images, right? \n\nYou type in shopping, you\u2019ll see more images of women than men. How does that affect our computer vision systems? Et cetera, et cetera. So, there\u2019s a lot of work there. \n\nI would say that the focus at AI2 has been on the beneficial use cases. So, there\u2019s some work to do to fight against the negative ones, but why do we even go into this in the first place. We go into why do we build this advanced technology? Why do we do this basic research? We do it because we see opportunities for technology to make the world a better place. \n\nAnd, of course, now when we\u2019re all \u2013 the entire international society is questing for a vaccine to COVID-19, I think that\u2019s a very important illustration of that, right? We are reliant on technology, and by the way, AI is heavily used there, but we\u2019re looking for technology to solve some of humanity\u2019s thorniest problems. And we\u2019re working to build what I would call \u201cbeneficial AI\u201d systems. \n\nKEVIN SCOTT: So, what do you think we collectively can do? And, like, you can interpret \u201cwe\u201d however you want \u2013 we the technology industry, we academia, we the governments of the world\u2019s nations can be doing to leverage the power that we\u2019re building with AI and to get people prepared?\n\nI mean, you mentioned numeracy, for instance, which is mathematical equivalent of literacy, which I think is at least as important as literacy in the modern world or, like, 21st century. \n\nBut, like, what are the other things, like, policy-wise, education-wise, investment-wise that we should be doing to, like, receive the benefit that AI is going to be able to create over the next handful of years? \n\nOREN ETZIONI: Well, in terms of policy, I think we do actually have to be very careful not to use the kind of blunt and slow and easily distorted instrument of regulation to harm the field. So, I would be very hesitant, for example, to regulate basic research. And I would, instead, look at specific applications and ask, \u201cOkay, if we\u2019re putting AI into vehicles, how do we make sure that it\u2019s safe for people? Or if we put AI into toys, how do we make sure that\u2019s appropriate for our kids, for example? The AI doesn\u2019t elicit confidential information from our kids or manipulate them in various ways.\u201d \n\nSo, I\u2019m a big believer in regulate the applications of AI, not the field on its own. I think some of the overarching regulatory ideas, for example, in the EU, there\u2019s the right to an explanation. And it sounds good, right? AI is opaque, it\u2019s confusing, these are called black box models. Surely, if an AI system gives us a conclusion, we have a right to an explanation, that sounds very appealing. \n\nActually, I think it\u2019s a lot trickier than that because there are really two kinds of explanations of AI models. One is explanations that are simple and understandable but turn out not to be accurate. They\u2019re not high-fidelity explanations, because the system is complex. And a great example of that is if you go to Netflix and it recommends a movie to you, they\u2019ve realized that people want to know, why did you recommend this movie? And say, \u201cWell, we recommended this movie because you liked that movie, right? We recommended Goodfellas because you liked The Godfather.\u201d\n\nWell, if you look under the hood, right, the model that they use is actually a lot more complicated than that. So, they gave me a really simple explanation that\u2019s just not true. So, that\u2019s one kind. \n\nThe other kind is I can give you a true explanation, but it\u2019ll be completely incomprehensible. So, now if the EU says, you know, you have a right to an explanation, what you\u2019re going to end up with is one of these two horns of the dilemma \u2013 something that\u2019s incomprehensible, or something that is inaccurate. \n\nSo, I think that it\u2019s really important that we are careful not to go with kind of popular notions like right to explain, but instead, think through what happens in particular contexts. \n\nKEVIN SCOTT: Yeah, I think that is an extraordinarily good point. These models are already at the complexity where they\u2019re as complex as some natural phenomenon. We\u2019re not able to explain many natural phenomena because, you know, when we get down to the point of like these are the electrostatic interactions of atoms that comprise this system. You have to look at the phenomenology of the system. It\u2019s why statistics is going to be such a really important skill for everyone. It\u2019s why understanding the scientific method and having an experimental mindset I think is important. \n\nI think this is such a good point about not deceiving ourselves that an incomprehensibly complex answer to a question of like \u201cWhy did this thing do what it did?\u201d even if it\u2019s couched in terms of language that we might otherwise understand, that\u2019s not real understanding. \n\nOREN ETZIONI: Exactly. And I\u2019m not suggesting that the solution is, hey, just trust us, you know, we\u2019re \u2013 we\u2019re all (inaudible, crosstalk) \n\nKEVIN SCOTT: Yeah, yeah, yeah, for sure \u2013 \n\nOREN ETZIONI: \u2013 going to work. But, again, going back to the auditing idea, rather than an explanation, if we want \u2013 you know, one of the most jarring ones are uses of AI in the criminal justice system, right? \n\nKEVIN SCOTT: Yes. \n\nOREN ETZIONI: To help make parole decisions and things like that. Well, we should audit these systems, test them for bias, right? The press should be doing that, the ACLU should be doing that, regulatory agencies should be doing that. But the solution is not to get some strange explanation for the machine. The solution is to be able to audit its behavior statistically and test it, hey, are you exhibiting some kind of demographic bias? \n\nKEVIN SCOTT: Yeah, I mean, one of the things we do at Microsoft is we have these two bodies inside of the company, this thing called the Office for Responsible AI that sits in our legal team. And we have this thing called Aether, that\u2019s the AI and ethics committee inside of the company.  \n \nWhat we do with both of these bodies is we try to have both the lawyers and the scientists thinking about how you inspect both the artifacts that you\u2019re building in your AI research, but their uses. And we have a very clearly defined notion of a sensitive use. And depending on how sensitive a use a particular model is being deployed in, we have different standards of auditing and scrutiny that go along with it. \n\nAnd, recommendations, like, for a criminal justice application, for instance, you may say that a model can only advise, like, we do not condone it making a final decision. You know, just so that there\u2019s always human review in the loop. \n\nOREN ETZIONI: I think that\u2019s smart. And I also think that this relates to another key principle when we think about both regulatory frameworks and ethical issues. Whose responsibility is it? The responsibility and liability has to ultimately rest with a person. You can\u2019t say, \u201cHey, you know, look, my car ran you over, it\u2019s an AI car, I don\u2019t know what it did, it\u2019s not my fault, right?\u201d You as the driver or maybe it\u2019s the manufacturer if there\u2019s some malfunction, but people have to be responsible for the behavior of the machines.  \n\nThe same way that, look, I\u2019ve got \u2013 the car\u2019s already a complex machine with 150 CPUs and so on, I can\u2019t say, \u201cOh, well, the car ran you over, I had very little to do with it.\u201d The same is true when I have an AI system. I have to be the one who\u2019s responsible for an ethical decision. So, very much agree with you there. \n\nKEVIN SCOTT: Yeah, so we are just about out of time, but before we go, I wanted to ask you, what do you do for fun outside of work? \n\nOREN ETZIONI: Well, I would say that spending time with people, you know, my family. Like everybody in the Northwest, you know, getting outdoors and hiking is fun. I also \u2013 I love team sports. My knees no longer tolerate it, but for many years, I played soccer and basketball.  \n\nSo, you know, do a variety of those things. But most recently, particularly under COVID, I have to admit that I\u2019ve developed a vice. And that is playing Bug House online. So, Bug House is team chess, right, where you have two players facing off two other players. And you have \u2013 used to be five minutes, now online three minutes is popular. \n\nSo, you have a three-minute game. And in that game, you have to defeat your opponent, working together with your partners. That is, if your partner is the white player and you\u2019re the black player, she might hand you a black piece, right, because she takes her opponent\u2019s black piece, she hands it to you. This is all mediated by the computer. And you place it on your board instead of making a move. So, it\u2019s a crazy, crazy game, which is what the phrase Bug House alludes to. And it has communication, it has adrenaline, it has stopwatch, you know, split-second timing, and it\u2019s a wonderful distraction from worrying about when we\u2019re going to have a vaccine.  \n\nKEVIN SCOTT: That sounds like a lot of fun. \nThis has been an amazing conversation. I\u2019m so happy to know that there are people like you \u2013 and institutions like AI2 that are not just advancing the state of the art, but like, thinking very, very carefully about how these technologies can have a positive benefit for society. So, like, thank you so much for the work you do and for being here with us for an hour today. \n\nOREN ETZIONI: Well, thank you, Kevin. I really appreciated the opportunity to talk to you and to talk to your audience. It\u2019s a real pleasure. \n\nKEVIN SCOTT: Awesome. \n\n[MUSIC]\t\n\nCHRISTINA WARREN: Well, that was Kevin\u2019s conversation with Oren Etzioni. Wow, you went through so many different paths and talked about so many different interesting things. \n\nFor you, Kevin, I\u2019m curious, as someone who works on the industry side of artificial intelligence, what excites you or I guess is most interesting to you about some of the stuff that Oren is pursuing from more of the academic perspective?  \n\nKEVIN SCOTT: Well, look, I think AI2 is doing some of the most interesting work in the field right now, and you sort of heard in our conversation, this giant leap forward that we have had in natural language processing and natural language understanding over the past handful of years. \n\nStarted at AI2 with their work on this technology called ELMO, which then resulted in BURT and Roberta and Turing NLG and GPT and a whole bunch of these technologies that really are reshaping how natural language and AI is working right now. \n\nOne of the things that Oren was chatting about that\u2019s really impressive both from a technical perspective as well as just beneficial use for society is the work that they\u2019re doing on Semantic Scholar, which is applying some of these really advanced AI technologies to the task of trying to understand and make more accessible the huge amount of scientific literature that the researchers of the world are producing right now. \n\nAnd things like that become even more important when you have a moment like we\u2019re in now with COVID, where getting that research digested and to the right people as quickly as humanly possible so that you really are able to get those right people to understand the salient points can just mean the difference between literal life and death as we\u2019re scrambling to develop therapies and vaccines for SARS coronavirus-2. \n\nSo, it\u2019s just wonderful that you have this combination of such incredibly clever people there who are also working on these problems that can create such benefit in the world. \n\nCHRISTINA WARREN: Yeah, no, I totally agree. And when he was talking about some of that work, I was thinking just about all the \u2013 the use cases and \u2013 and you, obviously, go to some of the most important ones, which would be, you know, life-and-death decisions. But just in general, the ability to really help get people the right information by you know translating and kind of digesting and getting the essence of those documents out. It\u2019s really powerful. \n\nAnd that\u2019s just talking about, you know, in one language. I think about what could happen when we talk about, you know, like, machine translation and that sort of work, too. I\u2019m excited about what GPT-3 and other things that I \u2013 that you know about that I read about and try to kind of understand promise and it\u2019s really exciting to think about. \n\nKEVIN SCOTT: Yeah, I think in general, it\u2019s an exciting time to be working on AI right now. And just a good reminder from this conversation today that it is equally important to be thinking about how you point that work in a direction that is safe and responsible and benefits the public good. \n\nCHRISTINA WARREN: What Oren is doing, he is still a professor. He works with students and he\u2019s training the next generation of people who \u2013 whether they\u2019re going to be researchers or people working in industry are going to be solving these problems and inspiring those next generation of thinkers and innovators is awesome, and I\u2019m glad we have people like him doing that kind of work. \n\nKEVIN SCOTT: Yeah, I mean, as I wrote about in my book and I\u2019ve talked about over and over and over again, we should be thinking about AI as a tool, and a tool that can enhance and augment the things that human beings are trying to do. And I think Oren raised a really good point in our conversation today around the important role that education has to play in preparing our future citizens and people even in the workforce today in being able to pick those tools up and make the best possible use of them. \n\nAnd it\u2019s a little bit different than, you know, the education system that we have right now, which is fundamentally engineered around the needs of an industrial economy. In the future, we may need to train people to better operate inside of an AI economy. \n\nCHRISTINA WARREN: Yeah, no, that\u2019s really interesting things to think about. And I also really liked when he was talking about how, you know, he thinks of AI as \u201caugmented\u201d intelligence, and I think that to your point, especially if we\u2019re thinking about having to train people to work inside an AI economy, that\u2019s where that kind of comes into place is being able to augment or in some cases supplement other types of learnings and other things that people are doing so that we can adjust and I guess be agile. \n\nKEVIN SCOTT: Yep, absolutely. \n\nCHRISTINA WARREN: Okay, well, that\u2019s a wrap. Thank you so much to Oren for joining us today. Also, buy Kevin\u2019s book or read it, because it\u2019s fantastic. Get it from your local library, your favorite local bookstore, wherever. It\u2019s awesome. \n\nAnd to our listeners, thank you for joining us. Thank you for being in this conversation. Send us a message anytime at behindthetech@Microsoft.com. And tell us what\u2019s on your mind. And please, stay safe out there. \n\nKEVIN SCOTT: See you next time. \n\n\n"}