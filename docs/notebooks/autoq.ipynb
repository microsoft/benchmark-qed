{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57a1db8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2025 Microsoft Corporation.\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(1, \"../../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29dacb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot find .env file\n"
     ]
    }
   ],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb39cd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "from pydantic import SecretStr\n",
    "\n",
    "from benchmark_qed.autod.data_processor.embedding import TextEmbedder\n",
    "from benchmark_qed.autod.io.text_unit import load_text_units\n",
    "from benchmark_qed.autoq.io.activity import (\n",
    "    save_activity_context,\n",
    ")\n",
    "from benchmark_qed.autoq.io.question import (\n",
    "    load_questions,\n",
    "    save_questions,\n",
    ")\n",
    "from benchmark_qed.config.llm_config import LLMConfig, LLMProvider\n",
    "from benchmark_qed.llm.factory import ModelFactory\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "if logging.getLogger(\"httpx\") is not None:\n",
    "    logging.getLogger(\"httpx\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9270eb",
   "metadata": {},
   "source": [
    "# AutoQ\n",
    "![AutoQ](../images/AutoQ.png)\n",
    "\n",
    "AutoQ is an automated approach to question generation that supports the following typology of information-seeking questions:\n",
    "\n",
    "- *Question Scope*: the extent of the dataset that the question addresses\n",
    "    - *Local* questions targeting specific details of a text corpus\n",
    "    - *Global* questions targeting general aspects of a text corpus (e.g., themes, concerns, opportunities)\n",
    "- *Question Source*: the information used to generate local and global questions\n",
    "    - *Data-driven* questions based on text sampled from the overall corpus\n",
    "    - *Activity-driven* questions based on potential activities consistent with the data\n",
    "\n",
    "This typology gives four major question types, generated using LLM-based methods. The question generation process generally consists of 2 main steps:\n",
    "1. *Candidate Generation*: Use an LLM model to generate a large pool of candidate questions, typically oversampled (based on a specified oversample factor) to ensure sufficient variety for downstream selection.\n",
    "2. *Ranking and Selection*: The candidate questions are clustered, ranked, and filtered using various metrics to select the final set of target questions.\n",
    "\n",
    "Below is a more detailed description of the question generation method for each question class:\n",
    "\n",
    "1. *Data-driven local questions*\n",
    "    - Sample texts are extracted from the input text corpus, with target text regions selected\n",
    "    - Candidate local questions are generated for each target text region using a two-step (extract+expand) process\n",
    "    - Candidate questions are clustered and ranked using semantic similarity-based metrics to select a smaller subset of best questions.\n",
    "    - Relevant claims are extracted for each question based on the sources texts in the corresponding text region\n",
    "    - (Optional): *assertions* are generated for each question based on the extracted claims. These assertions can then be used to evaluate assertion-based accuracy of RAG methods.\n",
    "    - Any abstract categories (e.g., themes) reflected by the sample text are captured\n",
    "3. *Data-driven global questions*\n",
    "    - For each abstract category with 2+ local questions, generate a global question\n",
    "    - Relevant claims are extracted for each global question by aggregating relevant claims from the referenced local questions.\n",
    "    - Candidate questions are clustered and ranked using counts of extracted claims' references and input local questions to select a smaller subset of best questions.\n",
    "    - (Optional): *assertions* are generated for each selected question based on the extracted claims. These assertions can then be used to evaluate assertion-based accuracy of RAG methods.\n",
    "4. *Activity-driven local questions*\n",
    "    - A dataset summary is generated from the sample texts using AutoD\n",
    "    - A set of {persona, task, relevant entities} is generated based on the dataset summary and sample texts\n",
    "    - Candidate local questions are generated for each {persona, task, entities} combination\n",
    "    - Candidate questions are clustered and ranked using entity similarity metrics to select a smaller subset of best questions.\n",
    "5. *Activity-driven global questions*\n",
    "    - Generate candidate global questions for each {dataset, persona, task} combination\n",
    "    - Candidate global questions are clustered and ranked using a similarity-based metric to select a smaller subset of representative questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23749b8c",
   "metadata": {},
   "source": [
    "## Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b271ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA CONFIGS\n",
    "INPUT_DATA_PATH = \"../../datasets/AP_news/raw_data\"\n",
    "OUTPUT_DATA_PATH = \"../../output/AP_news/processed_data\"\n",
    "OUTPUT_QUESTIONS_PATH = \"../../output/AP_news/questions\"\n",
    "TEXT_COLUMN = \"body_nitf\"\n",
    "METADATA_COLUMNS = [\"headline\", \"firstcreated\"]\n",
    "FILE_ENCODING = \"utf-8-sig\"\n",
    "\n",
    "# tokenizer used for chunking documents into text units\n",
    "ENCODING_MODEL = \"o200k_base\"\n",
    "CHUNK_SIZE = 600\n",
    "CHUNK_OVERLAP = 100\n",
    "\n",
    "# DATA SAMPLING CONFIGS\n",
    "# These configs control the breadth and depth of the selected data sample.\n",
    "# Adjust these parameters based on your data size and the number of questions to be generated (e.g. try increasing number of clusters if you want to generate more diverse questions)\n",
    "# The final sample size will be NUM_CLUSTERS * NUM_SAMPLES_PER_CLUSTER\n",
    "NUM_CLUSTERS = 20\n",
    "NUM_SAMPLES_PER_CLUSTER = 10\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# GENERAL QUESTION GENERATION CONFIGS\n",
    "# Number of questions to generate for each question class. You can also specify a different number of questions for each class.\n",
    "NUM_QUESTIONS = 10\n",
    "# Factor by which to overgenerate candidate questions (you can specify a different factor for each question class). These candidate questions will be ranked and filtered using a question sampler to select the final questions.\n",
    "OVERSAMPLE_FACTOR = 2.0\n",
    "\n",
    "# CONFIGS SPECIFIC TO ACTIVITY QUESTIONS\n",
    "# these configs should be adjusted based on the number of questions to be generated. Try increasing these configs if you want to generate more questions.\n",
    "NUM_PERSONAS = 5\n",
    "NUM_TASKS_PER_PERSONA = 2\n",
    "NUM_ENTITIES_PER_TASK = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ffbd099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL CONFIGS\n",
    "API_KEY = SecretStr(os.getenv(\"OPENAI_API_KEY\", \"\"))\n",
    "EMBEDDING_MODEL = \"text-embedding-3-large\"\n",
    "LLM_MODEL = \"gpt-4.1\"\n",
    "LLM_PARAMS = {\n",
    "    \"temperature\": 0.0,\n",
    "    \"seed\": 42,\n",
    "}  # adjust this based on your model. For example, some reasoning models do not support temperature settings\n",
    "CONCURRENT_REQUESTS = (\n",
    "    8  # Control for request concurrency. Adjust this based on your model capacity.\n",
    ")\n",
    "\n",
    "text_embedder = TextEmbedder(\n",
    "    ModelFactory.create_embedding_model(\n",
    "        LLMConfig(\n",
    "            model=EMBEDDING_MODEL,\n",
    "            api_key=API_KEY,\n",
    "            llm_provider=LLMProvider.OpenAIEmbedding,\n",
    "        )\n",
    "    )\n",
    ")\n",
    "llm = ModelFactory.create_chat_model(\n",
    "    model_config=LLMConfig(\n",
    "        model=LLM_MODEL,\n",
    "        api_key=API_KEY,\n",
    "        llm_provider=LLMProvider.OpenAIChat,\n",
    "        call_args=LLM_PARAMS,\n",
    "    )\n",
    ")\n",
    "token_encoder = tiktoken.get_encoding(ENCODING_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd6e165",
   "metadata": {},
   "source": [
    "## Data Sampling\n",
    "\n",
    "In this step, we load documents from the input folders, chunk them into text units, and embed all text units. We then sample a subset of text units using the specified number of clusters and number of samples for each cluster. These clustered sample texts will be used to ground the question generation process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db1cfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from benchmark_qed.autod.sampler.sample_gen import acreate_clustered_sample\n",
    "\n",
    "clustered_sample = await acreate_clustered_sample(\n",
    "    input_path=INPUT_DATA_PATH,\n",
    "    output_path=OUTPUT_DATA_PATH,\n",
    "    text_embedder=text_embedder,\n",
    "    num_clusters=NUM_CLUSTERS,\n",
    "    num_samples_per_cluster=NUM_SAMPLES_PER_CLUSTER,\n",
    "    input_type=\"json\",\n",
    "    text_tag=TEXT_COLUMN,\n",
    "    metadata_tags=METADATA_COLUMNS,\n",
    "    chunk_size=CHUNK_SIZE,\n",
    "    chunk_overlap=CHUNK_OVERLAP,\n",
    "    file_encoding=FILE_ENCODING,\n",
    "    token_encoding=ENCODING_MODEL,\n",
    "    random_seed=RANDOM_SEED,\n",
    ")\n",
    "print(\n",
    "    f\"Sampled {len(clustered_sample.sample_texts)} samples from {len(clustered_sample.text_units)} text units in {len(clustered_sample.documents)} documents.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ee0b96",
   "metadata": {},
   "source": [
    "## Data-Local Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11eb2cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:benchmark_qed.autoq.question_gen.data_questions.local_question_gen:Processing clusters 0 to 8 of 20 clusters...\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]INFO:benchmark_qed.autoq.question_gen.data_questions.local_question_gen:Generated 4 assertions for question: What reasons did Governor Jim Justice of West Virginia provide in March and April 2024 for vetoing House Bill 5105, which proposed eliminating vaccine requirements and expanding religious exemptions for students in public virtual schools, private schools, and parochial schools in West Virginia?\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.local_question_gen:Question: What reasons did Governor Jim Justice of West Virginia provide in March and April 2024 for vetoing House Bill 5105, which proposed eliminating vaccine requirements and expanding religious exemptions for students in public virtual schools, private schools, and parochial schools in West Virginia?. Intra-inter Similarity: 2.3893352569984407. Reference Coverage: 0.3\n",
      " 12%|█▎        | 1/8 [00:43<05:01, 43.03s/it]INFO:benchmark_qed.autoq.question_gen.data_questions.local_question_gen:Generated 4 assertions for question: What limits has the United States Environmental Protection Agency set for the chemicals PFOA and PFOS in drinking water as of April 2024, and what requirements must public water systems follow if these limits are exceeded?\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.local_question_gen:Question: What limits has the United States Environmental Protection Agency set for the chemicals PFOA and PFOS in drinking water as of April 2024, and what requirements must public water systems follow if these limits are exceeded?. Intra-inter Similarity: 3.6034028084923952. Reference Coverage: 0.4\n",
      " 25%|██▌       | 2/8 [00:44<01:51, 18.65s/it]INFO:benchmark_qed.autoq.question_gen.data_questions.local_question_gen:Generated 4 assertions for question: What is the purpose of Project Optimus, the initiative launched by the U.S. Food and Drug Administration to address dosing strategies in cancer drug development in the United States in recent years?\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.local_question_gen:Question: What is the purpose of Project Optimus, the initiative launched by the U.S. Food and Drug Administration to address dosing strategies in cancer drug development in the United States in recent years?. Intra-inter Similarity: 2.678710444687335. Reference Coverage: 0.3\n",
      " 38%|███▊      | 3/8 [00:46<00:55, 11.03s/it]INFO:benchmark_qed.autoq.question_gen.data_questions.local_question_gen:Generated 4 assertions for question: What safety protocols and procedures did Elara Caring have in place for visiting nurses making home visits to high-risk residences, such as the halfway house for sex offenders in Willimantic, Connecticut, at the time of Joyce Grayson's death in October 2023?\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.local_question_gen:Question: What safety protocols and procedures did Elara Caring have in place for visiting nurses making home visits to high-risk residences, such as the halfway house for sex offenders in Willimantic, Connecticut, at the time of Joyce Grayson's death in October 2023?. Intra-inter Similarity: 2.466195338500021. Reference Coverage: 0.1\n",
      " 50%|█████     | 4/8 [00:48<00:29,  7.45s/it]INFO:benchmark_qed.autoq.question_gen.data_questions.local_question_gen:Generated 5 assertions for question: What are the main differences between the proposed 2024 ballot measures regarding abortion access in Missouri, including the gestational limits and exceptions outlined by each measure?\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.local_question_gen:Question: What are the main differences between the proposed 2024 ballot measures regarding abortion access in Missouri, including the gestational limits and exceptions outlined by each measure?. Intra-inter Similarity: 2.371648942712633. Reference Coverage: 0.3\n",
      " 62%|██████▎   | 5/8 [00:48<00:14,  4.88s/it]INFO:benchmark_qed.autoq.question_gen.data_questions.local_question_gen:Generated 4 assertions for question: What legal rationale did the Texas Supreme Court provide in December 2023 for denying Katie Cox's request for an immediate abortion due to her pregnancy complications under the state's abortion ban?\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.local_question_gen:Question: What legal rationale did the Texas Supreme Court provide in December 2023 for denying Katie Cox's request for an immediate abortion due to her pregnancy complications under the state's abortion ban?. Intra-inter Similarity: 2.57519483955715. Reference Coverage: 0.3\n",
      " 75%|███████▌  | 6/8 [00:52<00:09,  4.52s/it]INFO:benchmark_qed.autoq.question_gen.data_questions.local_question_gen:Generated 5 assertions for question: During the 2024 legislative session in Mississippi, what are the key differences between the Medicaid expansion proposals advanced by the Mississippi House of Representatives and the Mississippi Senate regarding eligibility criteria and the number of people who would be covered?\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.local_question_gen:Question: During the 2024 legislative session in Mississippi, what are the key differences between the Medicaid expansion proposals advanced by the Mississippi House of Representatives and the Mississippi Senate regarding eligibility criteria and the number of people who would be covered?. Intra-inter Similarity: 3.4058984501600453. Reference Coverage: 0.8\n",
      " 88%|████████▊ | 7/8 [00:57<00:04,  4.46s/it]INFO:benchmark_qed.autoq.question_gen.data_questions.local_question_gen:Generated 5 assertions for question: What measures did hospitals in the United States implement during the winter of 2023-2024 in response to the increased cases of flu and COVID-19?\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.local_question_gen:Question: What measures did hospitals in the United States implement during the winter of 2023-2024 in response to the increased cases of flu and COVID-19?. Intra-inter Similarity: 2.121004012845286. Reference Coverage: 0.4\n",
      "100%|██████████| 8/8 [01:00<00:00,  7.52s/it]\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.local_question_gen:Processing clusters 8 to 16 of 20 clusters...\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]INFO:benchmark_qed.autoq.question_gen.data_questions.local_question_gen:Generated 3 assertions for question: What provision regarding compensation for personal injuries and future health claims is included in the $600 million class-action settlement related to the February 2023 Norfolk Southern train derailment in East Palestine, Ohio?\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.local_question_gen:Question: What provision regarding compensation for personal injuries and future health claims is included in the $600 million class-action settlement related to the February 2023 Norfolk Southern train derailment in East Palestine, Ohio?. Intra-inter Similarity: 3.4481348310523914. Reference Coverage: 0.2\n",
      " 12%|█▎        | 1/8 [00:48<05:42, 48.91s/it]INFO:benchmark_qed.autoq.question_gen.data_questions.local_question_gen:Generated 5 assertions for question: During February and March 2024 in Alabama, what effect did the Alabama Supreme Court's decision to recognize frozen embryos as children under state law have on the availability of in vitro fertilization services at fertility clinics in the state?\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.local_question_gen:Generated 3 assertions for question: During the measles outbreak at Manatee Bay Elementary School in Broward County, Florida in early 2024, what guidance did Florida Surgeon General Dr. Joseph Ladapo provide to parents regarding school attendance for children who had not received the measles vaccine, and how did this guidance compare to the recommendations of the Centers for Disease Control and Prevention?\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.local_question_gen:Question: During February and March 2024 in Alabama, what effect did the Alabama Supreme Court's decision to recognize frozen embryos as children under state law have on the availability of in vitro fertilization services at fertility clinics in the state?. Intra-inter Similarity: 3.0370252236795365. Reference Coverage: 1.0\n",
      " 25%|██▌       | 2/8 [00:50<02:06, 21.12s/it]INFO:benchmark_qed.autoq.question_gen.data_questions.local_question_gen:Question: During the measles outbreak at Manatee Bay Elementary School in Broward County, Florida in early 2024, what guidance did Florida Surgeon General Dr. Joseph Ladapo provide to parents regarding school attendance for children who had not received the measles vaccine, and how did this guidance compare to the recommendations of the Centers for Disease Control and Prevention?. Intra-inter Similarity: 2.7011165333196474. Reference Coverage: 0.3\n",
      " 38%|███▊      | 3/8 [00:50<00:58, 11.62s/it]INFO:benchmark_qed.autoq.question_gen.data_questions.local_question_gen:Generated 1 assertions for question: What is the exact wording used in the March 2024 amendment to Article 34 of the French Constitution that guarantees the right to abortion in France?\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.local_question_gen:Question: What is the exact wording used in the March 2024 amendment to Article 34 of the French Constitution that guarantees the right to abortion in France?. Intra-inter Similarity: 3.334422601509097. Reference Coverage: 0.2\n",
      " 50%|█████     | 4/8 [00:52<00:30,  7.55s/it]INFO:benchmark_qed.autoq.question_gen.data_questions.local_question_gen:Generated 5 assertions for question: What measures did Oregon Governor Tina Kotek, Portland Mayor Ted Wheeler, and Multnomah County Chair Jessica Vega Pederson implement in downtown Portland, Oregon, during the 90-day fentanyl state of emergency declared in early 2024?\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.local_question_gen:Generated 5 assertions for question: In the United States during 2022 and 2023, what methods have manufacturers of disposable e-cigarettes such as Elf Bar and other Chinese brands used to circumvent import restrictions and regulatory enforcement by the U.S. Food and Drug Administration and U.S. Customs and Border Protection?\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.local_question_gen:Question: In the United States during 2022 and 2023, what methods have manufacturers of disposable e-cigarettes such as Elf Bar and other Chinese brands used to circumvent import restrictions and regulatory enforcement by the U.S. Food and Drug Administration and U.S. Customs and Border Protection?. Intra-inter Similarity: 4.207378980000668. Reference Coverage: 0.7\n",
      " 62%|██████▎   | 5/8 [00:53<00:16,  5.42s/it]INFO:benchmark_qed.autoq.question_gen.data_questions.local_question_gen:Question: What measures did Oregon Governor Tina Kotek, Portland Mayor Ted Wheeler, and Multnomah County Chair Jessica Vega Pederson implement in downtown Portland, Oregon, during the 90-day fentanyl state of emergency declared in early 2024?. Intra-inter Similarity: 2.769448396838549. Reference Coverage: 0.1\n",
      " 75%|███████▌  | 6/8 [00:54<00:07,  3.65s/it]INFO:benchmark_qed.autoq.question_gen.data_questions.local_question_gen:Generated 5 assertions for question: What strategies have health and sleep experts in the United States and Mexico recommended in 2024 to help adults improve their sleep quality and duration, considering the cultural, occupational, and societal factors that contribute to insufficient sleep?\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.local_question_gen:Question: What strategies have health and sleep experts in the United States and Mexico recommended in 2024 to help adults improve their sleep quality and duration, considering the cultural, occupational, and societal factors that contribute to insufficient sleep?. Intra-inter Similarity: 2.7518472395864735. Reference Coverage: 0.7\n",
      " 88%|████████▊ | 7/8 [00:57<00:03,  3.60s/it]INFO:benchmark_qed.autoq.question_gen.data_questions.local_question_gen:Generated 5 assertions for question: What laws or proposed laws in 2024 have restricted or sought to restrict access to gender-affirming medical care for transgender minors and adults in the states of South Carolina, Missouri, Ohio, and Florida?\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.local_question_gen:Question: What laws or proposed laws in 2024 have restricted or sought to restrict access to gender-affirming medical care for transgender minors and adults in the states of South Carolina, Missouri, Ohio, and Florida?. Intra-inter Similarity: 2.5147989041187966. Reference Coverage: 0.9\n",
      "100%|██████████| 8/8 [00:58<00:00,  7.28s/it]\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.local_question_gen:Processing clusters 16 to 20 of 20 clusters...\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]INFO:benchmark_qed.autoq.question_gen.data_questions.local_question_gen:Generated 5 assertions for question: Following the events in December 2023 and January 2024, when U.S. Defense Secretary Lloyd Austin's prostate cancer diagnosis, surgery, and subsequent hospitalizations were not promptly disclosed to the White House, Congress, or the public, what procedural changes did the Pentagon make to its notification policies regarding the transfer of authority and disclosure of medical absences for senior officials?\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.local_question_gen:Question: Following the events in December 2023 and January 2024, when U.S. Defense Secretary Lloyd Austin's prostate cancer diagnosis, surgery, and subsequent hospitalizations were not promptly disclosed to the White House, Congress, or the public, what procedural changes did the Pentagon make to its notification policies regarding the transfer of authority and disclosure of medical absences for senior officials?. Intra-inter Similarity: 3.0951588499427025. Reference Coverage: 0.2\n",
      " 25%|██▌       | 1/4 [00:18<00:55, 18.49s/it]INFO:benchmark_qed.autoq.question_gen.data_questions.local_question_gen:Generated 5 assertions for question: What health conditions experienced by Pope Francis in late 2023 led to the cancellation of his planned travel from Vatican City to the COP28 climate conference in Dubai?\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.local_question_gen:Question: What health conditions experienced by Pope Francis in late 2023 led to the cancellation of his planned travel from Vatican City to the COP28 climate conference in Dubai?. Intra-inter Similarity: 3.5629691422891496. Reference Coverage: 0.5\n",
      " 50%|█████     | 2/4 [00:25<00:23, 11.67s/it]INFO:benchmark_qed.autoq.question_gen.data_questions.local_question_gen:Generated 5 assertions for question: During February and March 2024 in South Korea, what legal and administrative penalties could junior doctors who participated in strikes face if they did not comply with the South Korean government's order to return to work following the announcement to increase the national medical school enrollment cap?\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.local_question_gen:Question: During February and March 2024 in South Korea, what legal and administrative penalties could junior doctors who participated in strikes face if they did not comply with the South Korean government's order to return to work following the announcement to increase the national medical school enrollment cap?. Intra-inter Similarity: 3.5176016813629154. Reference Coverage: 0.9\n",
      " 75%|███████▌  | 3/4 [00:31<00:09,  9.04s/it]INFO:benchmark_qed.autoq.question_gen.data_questions.local_question_gen:Generated 5 assertions for question: How have the public duties of the British royal family in the United Kingdom been affected during February and March 2024 due to King Charles III's cancer diagnosis and Princess Kate's recovery from abdominal surgery?\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.local_question_gen:Question: How have the public duties of the British royal family in the United Kingdom been affected during February and March 2024 due to King Charles III's cancer diagnosis and Princess Kate's recovery from abdominal surgery?. Intra-inter Similarity: 3.519143457489235. Reference Coverage: 0.8\n",
      "100%|██████████| 4/4 [00:31<00:00,  8.00s/it]\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.local_question_gen:Generated 20 candidate questions from 20 clusters.\n",
      "INFO:benchmark_qed.autod.sampler.clustering.kmeans:Cluster sizes: min=1, max=5, mean=2.0\n",
      "INFO:benchmark_qed.autoq.sampler.question_sampler:Selected 10 questions from 20 candidates.\n"
     ]
    }
   ],
   "source": [
    "from benchmark_qed.autoq.question_gen.data_questions.local_question_gen import (\n",
    "    DataLocalQuestionGen,\n",
    ")\n",
    "\n",
    "# load clustered text sample (result from the data sampling step)\n",
    "# If you have previously run the data sampling step, you can load the sample from disk instead of re-running the data sampling step as the below example.\n",
    "# Otherwise, you can use clustered_sample.sample_texts directly\n",
    "sample_texts_df = pd.read_parquet(f\"{OUTPUT_DATA_PATH}/sample_texts.parquet\")\n",
    "sample_texts = load_text_units(df=sample_texts_df)\n",
    "\n",
    "data_local_generator = DataLocalQuestionGen(\n",
    "    llm=llm,\n",
    "    text_embedder=text_embedder,\n",
    "    text_units=sample_texts,\n",
    "    concurrent_coroutines=CONCURRENT_REQUESTS,\n",
    "    random_seed=RANDOM_SEED,\n",
    "    max_assertions=5, # set this to an integer value to limit the number of assertions generated. Set this to 0 to disable assertion generation\n",
    ")\n",
    "\n",
    "data_local_question_results = await data_local_generator.agenerate(\n",
    "    num_questions=NUM_QUESTIONS,\n",
    "    oversample_factor=OVERSAMPLE_FACTOR,\n",
    ")\n",
    "\n",
    "# save both candidate questions and the final selected questions\n",
    "save_questions(\n",
    "    data_local_question_results.selected_questions,\n",
    "    f\"{OUTPUT_QUESTIONS_PATH}/data_local_questions/\",\n",
    "    \"selected_questions\",\n",
    ")\n",
    "save_questions(\n",
    "    data_local_question_results.selected_questions,\n",
    "    f\"{OUTPUT_QUESTIONS_PATH}/data_local_questions/\",\n",
    "    \"selected_questions_text\",\n",
    "    question_text_only=True,\n",
    ")\n",
    "save_questions(\n",
    "    data_local_question_results.candidate_questions,\n",
    "    f\"{OUTPUT_QUESTIONS_PATH}/data_local_questions/\",\n",
    "    \"candidate_questions\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9eec03a",
   "metadata": {},
   "source": [
    "## Data Global Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b72211a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:benchmark_qed.autoq.question_gen.data_questions.global_question_gen:Number of initial categories: 117\n",
      "Number of valid candidate categories (i.e. categories with more than one input question): 12\n",
      "Number of questions to generate per candidate category: 2\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.global_question_gen:Processing categories 0 to 8 of 12 categories...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 20 candidate local questions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP CONTEXT: Created 1 batches from 24 simple claims\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP RESPONSES: Processing 1 batches in parallel\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP CONTEXT: Created 2 batches from 51 simple claims\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP RESPONSES: Processing 2 batches in parallel\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP CONTEXT: Created 2 batches from 96 simple claims\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP RESPONSES: Processing 2 batches in parallel\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP CONTEXT: Created 2 batches from 51 simple claims\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP RESPONSES: Processing 2 batches in parallel\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP RESPONSES: Successfully processed 1 out of 1 batches\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Merging 5 assertions from 1 batches\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Ranked 5 unique assertions by score and source count\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Selected 5 of 5 assertions within 183 tokens (limit: 32000)\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE RESPONSE: Consolidating 5 assertions to 5\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP CONTEXT: Created 1 batches from 39 simple claims\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP RESPONSES: Processing 1 batches in parallel\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP RESPONSES: Successfully processed 2 out of 2 batches\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Merging 7 assertions from 2 batches\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Ranked 7 unique assertions by score and source count\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Selected 7 of 7 assertions within 276 tokens (limit: 32000)\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE RESPONSE: Consolidating 7 assertions to 5\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP CONTEXT: Created 1 batches from 14 simple claims\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP RESPONSES: Processing 1 batches in parallel\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP CONTEXT: Created 1 batches from 50 simple claims\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP RESPONSES: Processing 1 batches in parallel\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP CONTEXT: Created 1 batches from 25 simple claims\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP RESPONSES: Processing 1 batches in parallel\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:Successfully consolidated 5 assertions into 4\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP RESPONSES: Successfully processed 2 out of 2 batches\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Merging 10 assertions from 2 batches\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Ranked 10 unique assertions by score and source count\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Selected 10 of 10 assertions within 455 tokens (limit: 32000)\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE RESPONSE: Consolidating 10 assertions to 5\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP RESPONSES: Successfully processed 2 out of 2 batches\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Merging 7 assertions from 2 batches\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Ranked 7 unique assertions by score and source count\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Selected 7 of 7 assertions within 291 tokens (limit: 32000)\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE RESPONSE: Consolidating 7 assertions to 5\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:Successfully consolidated 7 assertions into 3\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP RESPONSES: Successfully processed 1 out of 1 batches\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Merging 5 assertions from 1 batches\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Ranked 5 unique assertions by score and source count\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Selected 5 of 5 assertions within 201 tokens (limit: 32000)\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE RESPONSE: Consolidating 5 assertions to 5\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP RESPONSES: Successfully processed 1 out of 1 batches\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Merging 5 assertions from 1 batches\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Ranked 5 unique assertions by score and source count\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Selected 5 of 5 assertions within 179 tokens (limit: 32000)\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE RESPONSE: Consolidating 5 assertions to 5\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP RESPONSES: Successfully processed 1 out of 1 batches\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Merging 5 assertions from 1 batches\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Ranked 5 unique assertions by score and source count\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Selected 5 of 5 assertions within 179 tokens (limit: 32000)\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE RESPONSE: Consolidating 5 assertions to 5\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP RESPONSES: Successfully processed 1 out of 1 batches\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Merging 5 assertions from 1 batches\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Ranked 5 unique assertions by score and source count\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Selected 5 of 5 assertions within 209 tokens (limit: 32000)\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE RESPONSE: Consolidating 5 assertions to 5\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:Successfully consolidated 10 assertions into 5\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:Successfully consolidated 7 assertions into 5\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:Successfully consolidated 5 assertions into 4\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP CONTEXT: Created 1 batches from 20 simple claims\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP RESPONSES: Processing 1 batches in parallel\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:Successfully consolidated 5 assertions into 4\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:Successfully consolidated 5 assertions into 4\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:Successfully consolidated 5 assertions into 4\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP CONTEXT: Created 2 batches from 61 simple claims\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP RESPONSES: Processing 2 batches in parallel\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP CONTEXT: Created 3 batches from 108 simple claims\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP RESPONSES: Processing 3 batches in parallel\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP CONTEXT: Created 2 batches from 65 simple claims\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP RESPONSES: Processing 2 batches in parallel\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP RESPONSES: Successfully processed 1 out of 1 batches\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Merging 5 assertions from 1 batches\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Ranked 5 unique assertions by score and source count\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Selected 5 of 5 assertions within 183 tokens (limit: 32000)\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE RESPONSE: Consolidating 5 assertions to 5\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP CONTEXT: Created 1 batches from 38 simple claims\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP RESPONSES: Processing 1 batches in parallel\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP CONTEXT: Created 1 batches from 15 simple claims\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP RESPONSES: Processing 1 batches in parallel\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP RESPONSES: Successfully processed 2 out of 2 batches\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Merging 10 assertions from 2 batches\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Ranked 10 unique assertions by score and source count\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Selected 10 of 10 assertions within 359 tokens (limit: 32000)\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE RESPONSE: Consolidating 10 assertions to 5\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP CONTEXT: Created 2 batches from 69 simple claims\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP RESPONSES: Processing 2 batches in parallel\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP RESPONSES: Successfully processed 3 out of 3 batches\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Merging 15 assertions from 3 batches\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Ranked 15 unique assertions by score and source count\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Selected 15 of 15 assertions within 566 tokens (limit: 32000)\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE RESPONSE: Consolidating 15 assertions to 5\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP RESPONSES: Successfully processed 2 out of 2 batches\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Merging 10 assertions from 2 batches\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Ranked 10 unique assertions by score and source count\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Selected 10 of 10 assertions within 376 tokens (limit: 32000)\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE RESPONSE: Consolidating 10 assertions to 5\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP CONTEXT: Created 1 batches from 18 simple claims\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP RESPONSES: Processing 1 batches in parallel\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:Successfully consolidated 5 assertions into 4\n",
      " 12%|█▎        | 1/8 [05:17<37:00, 317.14s/it]INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP RESPONSES: Successfully processed 1 out of 1 batches\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Merging 5 assertions from 1 batches\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Ranked 5 unique assertions by score and source count\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Selected 5 of 5 assertions within 198 tokens (limit: 32000)\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE RESPONSE: Consolidating 5 assertions to 5\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:Successfully consolidated 10 assertions into 5\n",
      " 25%|██▌       | 2/8 [05:20<13:16, 132.79s/it]INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP RESPONSES: Successfully processed 1 out of 1 batches\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Merging 5 assertions from 1 batches\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Ranked 5 unique assertions by score and source count\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Selected 5 of 5 assertions within 173 tokens (limit: 32000)\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE RESPONSE: Consolidating 5 assertions to 5\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:Successfully consolidated 15 assertions into 5\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:Successfully consolidated 10 assertions into 4\n",
      " 50%|█████     | 4/8 [05:25<02:59, 44.87s/it] INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP RESPONSES: Successfully processed 2 out of 2 batches\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Merging 10 assertions from 2 batches\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Ranked 10 unique assertions by score and source count\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Selected 10 of 10 assertions within 394 tokens (limit: 32000)\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE RESPONSE: Consolidating 10 assertions to 5\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:Successfully consolidated 5 assertions into 4\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:Successfully consolidated 5 assertions into 3\n",
      " 62%|██████▎   | 5/8 [05:26<01:27, 29.29s/it]INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP RESPONSES: Successfully processed 1 out of 1 batches\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Merging 5 assertions from 1 batches\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Ranked 5 unique assertions by score and source count\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Selected 5 of 5 assertions within 205 tokens (limit: 32000)\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE RESPONSE: Consolidating 5 assertions to 5\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:Successfully consolidated 10 assertions into 5\n",
      " 88%|████████▊ | 7/8 [05:30<00:15, 15.44s/it]INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:Successfully consolidated 5 assertions into 3\n",
      "100%|██████████| 8/8 [05:31<00:00, 41.41s/it]\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.global_question_gen:Processing categories 8 to 12 of 12 categories...\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP CONTEXT: Created 1 batches from 21 simple claims\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP RESPONSES: Processing 1 batches in parallel\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP CONTEXT: Created 1 batches from 10 simple claims\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP RESPONSES: Processing 1 batches in parallel\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP CONTEXT: Created 1 batches from 14 simple claims\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP RESPONSES: Processing 1 batches in parallel\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP RESPONSES: Successfully processed 1 out of 1 batches\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Merging 5 assertions from 1 batches\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Ranked 5 unique assertions by score and source count\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Selected 5 of 5 assertions within 176 tokens (limit: 32000)\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE RESPONSE: Consolidating 5 assertions to 5\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:Successfully consolidated 5 assertions into 3\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP RESPONSES: Successfully processed 1 out of 1 batches\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Merging 5 assertions from 1 batches\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Ranked 5 unique assertions by score and source count\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Selected 5 of 5 assertions within 168 tokens (limit: 32000)\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE RESPONSE: Consolidating 5 assertions to 5\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP RESPONSES: Successfully processed 1 out of 1 batches\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Merging 5 assertions from 1 batches\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Ranked 5 unique assertions by score and source count\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Selected 5 of 5 assertions within 173 tokens (limit: 32000)\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE RESPONSE: Consolidating 5 assertions to 5\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP CONTEXT: Created 1 batches from 16 simple claims\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP RESPONSES: Processing 1 batches in parallel\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:Successfully consolidated 5 assertions into 3\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:Successfully consolidated 5 assertions into 4\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP RESPONSES: Successfully processed 1 out of 1 batches\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Merging 5 assertions from 1 batches\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Ranked 5 unique assertions by score and source count\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Selected 5 of 5 assertions within 188 tokens (limit: 32000)\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE RESPONSE: Consolidating 5 assertions to 5\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP CONTEXT: Created 1 batches from 8 simple claims\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP RESPONSES: Processing 1 batches in parallel\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:Successfully consolidated 5 assertions into 4\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP RESPONSES: Successfully processed 1 out of 1 batches\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Merging 5 assertions from 1 batches\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Ranked 5 unique assertions by score and source count\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Selected 5 of 5 assertions within 176 tokens (limit: 32000)\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE RESPONSE: Consolidating 5 assertions to 5\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP CONTEXT: Created 1 batches from 16 simple claims\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP RESPONSES: Processing 1 batches in parallel\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:Successfully consolidated 5 assertions into 2\n",
      " 25%|██▌       | 1/4 [00:48<02:26, 48.69s/it]INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP RESPONSES: Successfully processed 1 out of 1 batches\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Merging 5 assertions from 1 batches\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Ranked 5 unique assertions by score and source count\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Selected 5 of 5 assertions within 182 tokens (limit: 32000)\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE RESPONSE: Consolidating 5 assertions to 5\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP CONTEXT: Created 1 batches from 19 simple claims\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP RESPONSES: Processing 1 batches in parallel\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:Successfully consolidated 5 assertions into 3\n",
      " 50%|█████     | 2/4 [00:55<00:48, 24.23s/it]INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP CONTEXT: Created 1 batches from 17 simple claims\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP RESPONSES: Processing 1 batches in parallel\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP RESPONSES: Successfully processed 1 out of 1 batches\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Merging 5 assertions from 1 batches\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Ranked 5 unique assertions by score and source count\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Selected 5 of 5 assertions within 175 tokens (limit: 32000)\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE RESPONSE: Consolidating 5 assertions to 5\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:MAP RESPONSES: Successfully processed 1 out of 1 batches\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Merging 5 assertions from 1 batches\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Ranked 5 unique assertions by score and source count\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE CONTEXT: Selected 5 of 5 assertions within 189 tokens (limit: 32000)\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:REDUCE RESPONSE: Consolidating 5 assertions to 5\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:Successfully consolidated 5 assertions into 4\n",
      " 75%|███████▌  | 3/4 [01:05<00:17, 17.57s/it]INFO:benchmark_qed.autoq.question_gen.data_questions.assertion_gen.global_claim_assertion_gen:Successfully consolidated 5 assertions into 5\n",
      "100%|██████████| 4/4 [01:06<00:00, 16.59s/it]\n",
      "INFO:benchmark_qed.autoq.question_gen.data_questions.global_question_gen:Generated 24 candidate questions from 20 local questions.\n",
      "INFO:benchmark_qed.autod.sampler.clustering.kmeans:Cluster sizes: min=1, max=4, mean=2.4\n",
      "INFO:benchmark_qed.autoq.sampler.question_sampler:Selected 10 questions from 24 candidates.\n"
     ]
    }
   ],
   "source": [
    "from benchmark_qed.autoq.question_gen.data_questions.global_question_gen import (\n",
    "    DataGlobalQuestionGen,\n",
    ")\n",
    "\n",
    "# Load candidate questions (result from the data local question generation step)\n",
    "# Please note that we load all the candidate local questions (not just the selected ones) as that gives us a bigger pool of local questions to aggregate from.\n",
    "# If you have previously run the data local question generation step, you can load the candidate questions from disk instead of re-running the data local question generation step as the below example.\n",
    "# Otherwise, you can use data_local_question_results.candidate_questions directly\n",
    "local_questions = load_questions(\n",
    "    f\"{OUTPUT_QUESTIONS_PATH}/data_local_questions/candidate_questions.json\"\n",
    ")\n",
    "print(f\"Loaded {len(local_questions)} candidate local questions.\")\n",
    "\n",
    "data_global_generator = DataGlobalQuestionGen(\n",
    "    llm=llm,\n",
    "    text_embedder=text_embedder,\n",
    "    local_questions=local_questions,\n",
    "    concurrent_coroutines=CONCURRENT_REQUESTS,\n",
    "    random_seed=RANDOM_SEED,\n",
    "    max_assertions=5,  # set this to an integer value to limit the number of assertions generated. Set this to 0 to disable assertion generation\n",
    ")\n",
    "\n",
    "data_global_question_results = await data_global_generator.agenerate(\n",
    "    num_questions=NUM_QUESTIONS,\n",
    "    oversample_factor=OVERSAMPLE_FACTOR,\n",
    ")\n",
    "\n",
    "# save both candidate questions and the final selected questions\n",
    "save_questions(\n",
    "    data_global_question_results.selected_questions,\n",
    "    f\"{OUTPUT_QUESTIONS_PATH}/data_global_questions/\",\n",
    "    \"selected_questions\",\n",
    ")\n",
    "save_questions(\n",
    "    data_global_question_results.selected_questions,\n",
    "    f\"{OUTPUT_QUESTIONS_PATH}/data_global_questions/\",\n",
    "    \"selected_questions_text\",\n",
    "    question_text_only=True,\n",
    ")\n",
    "save_questions(\n",
    "    data_global_question_results.candidate_questions,\n",
    "    f\"{OUTPUT_QUESTIONS_PATH}/data_global_questions/\",\n",
    "    \"candidate_questions\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb1549d",
   "metadata": {},
   "source": [
    "## Activity Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd3ab66",
   "metadata": {},
   "source": [
    "### Generate Activity Context\n",
    "\n",
    "Generate personas, their associated tasks, and relevant entities used to ground the activity-based question generation process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5789553",
   "metadata": {},
   "outputs": [],
   "source": [
    "from benchmark_qed.autoq.question_gen.activity_questions.context_gen.activity_context_gen import (\n",
    "    ActivityContextGen,\n",
    ")\n",
    "\n",
    "# load clustered text sample (result from the data sampling step)\n",
    "# If you have previously run the data sampling step, you can load the sample from disk instead of re-running the data sampling step as the below example.\n",
    "# Otherwise, you can use clustered_sample.sample_texts directly\n",
    "sample_texts_df = pd.read_parquet(f\"{OUTPUT_DATA_PATH}/sample_texts.parquet\")\n",
    "sample_texts = load_text_units(\n",
    "    df=sample_texts_df, attributes_cols=[\"is_representative\"]\n",
    ")\n",
    "\n",
    "activity_generator = ActivityContextGen(\n",
    "    llm=llm,\n",
    "    text_embedder=text_embedder,\n",
    "    token_encoder=token_encoder,\n",
    "    text_units=sample_texts,\n",
    "    concurrent_coroutines=CONCURRENT_REQUESTS,\n",
    ")\n",
    "\n",
    "activity_context = await activity_generator.agenerate(\n",
    "    num_personas=NUM_PERSONAS,\n",
    "    num_tasks=NUM_TASKS_PER_PERSONA,\n",
    "    num_entities_per_task=NUM_ENTITIES_PER_TASK,\n",
    "    oversample_factor=OVERSAMPLE_FACTOR,\n",
    "    use_representative_samples_only=True,  # if True, we will only use a subset of representative samples from the clustered texts to generate activity context (for efficiency). If False, we will use all the samples in the clustered texts.\n",
    ")\n",
    "\n",
    "save_activity_context(activity_context, f\"{OUTPUT_QUESTIONS_PATH}/context/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9671cf9f",
   "metadata": {},
   "source": [
    "### Generate Activity Local Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3269838e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from benchmark_qed.autoq.data_model.activity import ActivityContext\n",
    "from benchmark_qed.autoq.question_gen.activity_questions.local_question_gen import (\n",
    "    ActivityLocalQuestionGen,\n",
    ")\n",
    "\n",
    "# load activity context (result from the activity context generation step)\n",
    "# If you have previously run the activity context generation step, you can load the context from disk instead of re-running the activity context generation step as the below example.\n",
    "activity_context = ActivityContext(\n",
    "    **json.loads(\n",
    "        Path(f\"{OUTPUT_QUESTIONS_PATH}/context/activity_context_full.json\").read_text()\n",
    "    )\n",
    ")\n",
    "print(f\"Loaded {len(activity_context.task_contexts)} tasks.\")\n",
    "\n",
    "activity_local_generator = ActivityLocalQuestionGen(\n",
    "    llm=llm,\n",
    "    text_embedder=text_embedder,\n",
    "    activity_context=activity_context,\n",
    "    concurrent_coroutines=CONCURRENT_REQUESTS,\n",
    "    random_seed=RANDOM_SEED,\n",
    ")\n",
    "\n",
    "activity_local_question_results = await activity_local_generator.agenerate(\n",
    "    num_questions=NUM_QUESTIONS,\n",
    "    oversample_factor=OVERSAMPLE_FACTOR,\n",
    ")\n",
    "\n",
    "# save both candidate questions and the final selected questions\n",
    "save_questions(\n",
    "    activity_local_question_results.selected_questions,\n",
    "    f\"{OUTPUT_QUESTIONS_PATH}/activity_local_questions/\",\n",
    "    \"selected_questions\",\n",
    ")\n",
    "save_questions(\n",
    "    activity_local_question_results.selected_questions,\n",
    "    f\"{OUTPUT_QUESTIONS_PATH}/activity_local_questions/\",\n",
    "    \"selected_questions_text\",\n",
    "    question_text_only=True,\n",
    ")\n",
    "save_questions(\n",
    "    activity_local_question_results.candidate_questions,\n",
    "    f\"{OUTPUT_QUESTIONS_PATH}/activity_local_questions/\",\n",
    "    \"candidate_questions\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17c8c15",
   "metadata": {},
   "source": [
    "### Generate Activity Global Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5b229e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from benchmark_qed.autoq.question_gen.activity_questions.global_question_gen import (\n",
    "    ActivityGlobalQuestionGen,\n",
    ")\n",
    "\n",
    "# load activity context (result from the activity context generation step)\n",
    "# If you have previously run the activity context generation step, you can load the context from disk instead of re-running the activity context generation step as the below example.\n",
    "activity_context = ActivityContext(\n",
    "    **json.loads(\n",
    "        Path(f\"{OUTPUT_QUESTIONS_PATH}/context/activity_context_full.json\").read_text()\n",
    "    )\n",
    ")\n",
    "print(f\"Loaded {len(activity_context.task_contexts)} tasks.\")\n",
    "\n",
    "activity_global_generator = ActivityGlobalQuestionGen(\n",
    "    llm=llm,\n",
    "    text_embedder=text_embedder,\n",
    "    activity_context=activity_context,\n",
    "    concurrent_coroutines=CONCURRENT_REQUESTS,\n",
    "    random_seed=RANDOM_SEED,\n",
    ")\n",
    "\n",
    "activity_global_question_results = await activity_global_generator.agenerate(\n",
    "    num_questions=NUM_QUESTIONS,\n",
    "    oversample_factor=OVERSAMPLE_FACTOR,\n",
    ")\n",
    "\n",
    "# save both candidate questions and the final selected questions\n",
    "save_questions(\n",
    "    activity_global_question_results.selected_questions,\n",
    "    f\"{OUTPUT_QUESTIONS_PATH}/activity_global_questions/\",\n",
    "    \"selected_questions\",\n",
    ")\n",
    "save_questions(\n",
    "    activity_global_question_results.selected_questions,\n",
    "    f\"{OUTPUT_QUESTIONS_PATH}/activity_global_questions/\",\n",
    "    \"selected_questions_text\",\n",
    "    question_text_only=True,\n",
    ")\n",
    "save_questions(\n",
    "    activity_global_question_results.candidate_questions,\n",
    "    f\"{OUTPUT_QUESTIONS_PATH}/activity_global_questions/\",\n",
    "    \"candidate_questions\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "benchmark-qed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
